{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file containing multiple genome and read utility functions\n",
    "\n",
    "from bm_preproc import *\n",
    "from kmer_index import *\n",
    "import bisect\n",
    "\n",
    "class Read:\n",
    "    '''Class for reads in case we need to ever do anything else with it'''\n",
    "    \n",
    "    def __init__(self,seq,quality,length,num=1):\n",
    "        self.seq=seq\n",
    "        self.qual=quality\n",
    "        self.len=length\n",
    "        self.num=num\n",
    "        \n",
    "def readGenome(file):\n",
    "    '''function to read and return a genome as one string in fasta format'''\n",
    "    genome =  ''\n",
    "    f=open(file)\n",
    "    for line in f:\n",
    "        if line[0] == \">\": #ignoring the name of the genome\n",
    "            pass\n",
    "        else:\n",
    "            genome += line.strip()\n",
    "    f.close()\n",
    "    return genome\n",
    "\n",
    "def readFastQ(file):\n",
    "    '''function to read multiple reads (as a list of class Read instances) from a fastq file format'''\n",
    "    reads = []\n",
    "    f=open(file)\n",
    "    while f.readline(): # reading in the name\n",
    "        seq=f.readline().strip().upper() # reading in the sequence\n",
    "        f.readline() # reading in the + line\n",
    "        qual=f.readline().strip() #readling in the quality line\n",
    "        reads.append(Read(seq,qual,len(seq)))\n",
    "    f.close()\n",
    "    return reads        \n",
    "    \n",
    "def reverseCompliment(seq):\n",
    "    '''function to return the reverse complement of given sequence'''\n",
    "    compliment = {'A':'T','T':'A','C':'G','G':'C','N':'N'} # dictionary of base compliments\n",
    "    revComp = ''\n",
    "    for c in seq:\n",
    "        revComp = compliment[c] + revComp\n",
    "    return revComp\n",
    "\n",
    "def naive_match(pattern,text,st_aw=False,mismatch=0):\n",
    "    '''function to return the occurances of pattern in given text, \n",
    "    last argument should be passed as True for searching for the rev compliment of the pattern as well'''\n",
    "    occurances = []\n",
    "    num_aligns = 0 # counting number of \n",
    "    num_char_comp = 0\n",
    "    len_p = len(pattern)\n",
    "    len_t = len(text)\n",
    "    \n",
    "    rev_same=False\n",
    "    if st_aw: # calculate the reverse compliment if argument is true\n",
    "        revP = reverseCompliment(pattern)\n",
    "        if pattern == revP: # reverse compliment is the same\n",
    "            rev_same = True \n",
    "        \n",
    "    for i in range(len_t-len_p+1): # iterate over all possible indices\n",
    "        notMatch = 0\n",
    "        num_aligns += 1\n",
    "        \n",
    "        for j in range(len_p): # for every character in current possible alignment\n",
    "            num_char_comp += 1\n",
    "            if pattern[j] != text[i+j]: # if any character not equal, set match False and take a break\n",
    "                notMatch+=1\n",
    "                if notMatch > mismatch: # if number of mismtaches are more than what we allow\n",
    "                    break\n",
    "        if notMatch <= mismatch: # if all characters are same\n",
    "            occurances.append(i)\n",
    "\n",
    "        if st_aw and not rev_same: # if the reverse compliment also needs to be checked\n",
    "            notMatch = 0\n",
    "            for j in range(len_p): # for every character in current possible alignment\n",
    "                if revP[j] != text[i+j]: # if any character not equal, set match False and take a break\n",
    "                    notMatch+=1\n",
    "                    if notMatch > mismatch: # if number of mismtaches are more than what we allow\n",
    "                        break\n",
    "            if notMatch <= mismatch: # if all characters are same\n",
    "                occurances.append(i)\n",
    "            \n",
    "    return occurances, num_aligns, num_char_comp\n",
    "\n",
    "\n",
    "def boyer_moore(pattern,text,bm_obj):\n",
    "    '''function for read alignment using Boyer Moore algorithm, right now does not include \n",
    "    reverse complement and looks for exact match without mismatches'''\n",
    "    \n",
    "    len_p = len(pattern)\n",
    "    len_t = len(text)\n",
    "    num_align = 0\n",
    "    num_char_comp = 0\n",
    "    occurances = []\n",
    "    i = 0 #iterator for alignments\n",
    "    \n",
    "    while i < len_t - len_p + 1: #for each alignment\n",
    "        \n",
    "        num_align += 1\n",
    "        match = True\n",
    "        shift = 1 # if nothing, increment alignment by this much\n",
    "        \n",
    "        for j in range(len_p-1,-1,-1): #for each character in the alignment, starting with the end of the pattern\n",
    "            num_char_comp += 1\n",
    "            \n",
    "            if pattern[j] != text[i+j]: #mismatch occurs\n",
    "                match = False\n",
    "                shift_bc = bm_obj.bad_character_rule(j,text[i+j]) # calculate shift using the bad character rule\n",
    "                shift_gs = bm_obj.good_suffix_rule(j) # calculate shift using the good suffix rule\n",
    "                shift = max(shift_bc,shift_gs,1) # take the maximum that you can shift\n",
    "                break \n",
    "                \n",
    "        if match: # if it matches\n",
    "            occurances.append(i)\n",
    "            shift = bm_obj.match_skip() # shifts if string matches exactly\n",
    "            \n",
    "        i += shift\n",
    "    \n",
    "    return occurances,num_align,num_char_comp\n",
    "\n",
    "\n",
    "def pigeon_hole_index(pattern, text, index_t, mismatch = 0):\n",
    "    '''approximate matching algorithm with number of mismatches using the pigeon hole principle and indexing'''\n",
    "    \n",
    "    len_p = len(pattern)\n",
    "    len_t = len(text)\n",
    "    divisions = mismatch + 1\n",
    "    len_k = int(len_p/divisions) # length of the k-mer\n",
    "    \n",
    "    occurances = []\n",
    "    \n",
    "    if len_p % divisions != 0 or len_k != index_t.k: \n",
    "        print('Cannot use the index as the length of the pattern, number of mismatches, and kmer size not compatible')\n",
    "        print('Returning empty list')\n",
    "        return occurances\n",
    "    \n",
    "    for i in range(0,len_p,len_k): # for every division of the pattern\n",
    "        kmer = pattern[i:i+len_k]\n",
    "        hits = index_t.query(kmer) # places where this kmer exists in the text\n",
    "        print(len(hits))\n",
    "        \n",
    "        for h in hits: # for each of the places where this kmer is found, now we have to check if rest of the pattern matches\n",
    "    \n",
    "            if h - i in occurances: # if we already have this offset in the occurances list\n",
    "                continue\n",
    "                \n",
    "            num_mismatch = 0\n",
    "            \n",
    "            for b in range(i): # for every character before the current kmer in the pattern\n",
    "                \n",
    "                if pattern[b] != text[h-i+b]: # h-i+b is the index in the text for this particular pattern char\n",
    "                    num_mismatch += 1\n",
    "                    \n",
    "                    if num_mismatch > mismatch: # if more than number of mismatched allowed, then break\n",
    "                        break\n",
    "                        \n",
    "            if num_mismatch <= mismatch: # now compare the pattern ahead of the current kmer\n",
    "                \n",
    "                for a in range(i+len_k,len_p): # for every char after the current kmer\n",
    "                    \n",
    "                    if pattern[a] != text[h-i+a]: #h-i+a is the index in the text for this particular pattern char\n",
    "                        num_mismatch += 1\n",
    "                        \n",
    "                        if num_mismatch > mismatch:\n",
    "                            break\n",
    "                            \n",
    "            if num_mismatch <= mismatch: # found a match with allowed mismatches\n",
    "                occurances.append(int(h-i)) # offset on the text where this string matches            \n",
    "    \n",
    "    return occurances # get only unique occurances\n",
    "\n",
    "\n",
    "def edit_dist_match(pattern,text):\n",
    "    \n",
    "    '''function to return the edit distance of the best match between pattern inside text'''\n",
    "    len_p = len(pattern)\n",
    "    len_t = len(text)\n",
    "    \n",
    "    Matrix = [[0 for i in range(len_t+1)] for j in range(len_p+1)]  # the dynamic programming matrix, initialized as zeros\n",
    "    for i in range(1,len_p+1): # initializing the first column as the edit distance between an empty string and the pattern\n",
    "        Matrix[i][0] = i\n",
    "        \n",
    "    #print(Matrix)\n",
    "        \n",
    "    # fill the test of the matrix\n",
    "    for p in range(1,len_p+1): # for every row\n",
    "        \n",
    "        for t in range(1,len_t+1): # for every column\n",
    "            \n",
    "            dist_top = Matrix[p-1][t] + 1 # edit distance from the top + 1 for deletion in the text\n",
    "            dist_left = Matrix[p][t-1] + 1 # edit distance from the left +1 for deletion in the pattern\n",
    "            \n",
    "            if pattern[p-1] == text[t-1]: # if the two current bases are the same (-1 as we are starting from 1 here)\n",
    "                dist_diag = Matrix[p-1][t-1]\n",
    "            else:\n",
    "                dist_diag = Matrix[p-1][t-1] + 1 # one added for substitution\n",
    "                \n",
    "            Matrix[p][t] = min(dist_top,dist_left,dist_diag)\n",
    "            \n",
    "    #print(Matrix)\n",
    "    return min(Matrix[len_p]) # the minimum edit distance for the full pattern\n",
    "\n",
    "\n",
    "def overlap(read_suf,read_pre,min_length):\n",
    "    \n",
    "    '''function to return the length of the longest overlap between suffix of read_suf and prefix of read read_pre'''\n",
    "    if len(read_suf) < min_length or len(read_pre) < min_length: # if any of the reads is less than the min length\n",
    "        return 0\n",
    "    \n",
    "    min_kmer = read_pre[:min_length] # the minimum prefix that needs to be present in read_suf\n",
    "    start = 0\n",
    "    while start != -1: # while we can still find min_kmer in read_suf\n",
    "        \n",
    "        start = read_suf.find(min_kmer,start)\n",
    "        if start != -1: # found occurance, check if the rest if the string matches\n",
    "            if read_pre.startswith(read_suf[start:]): # if read_pre starts with rest of the suffix, then it is true\n",
    "                return len(read_suf)-start\n",
    "            else:\n",
    "                start+=min_length # move past the current match\n",
    "                \n",
    "    return 0 # if it comes here, then no more matches and we did not find what we aere looking for   \n",
    "\n",
    "\n",
    "def calc_overlap_graph(reads,min_length):\n",
    "    \n",
    "    '''function to return the edges and their weights of the overlap graph with edges between reads that overlap by atleast min_length'''\n",
    "    \n",
    "    edges = [] # list of edges in the graph\n",
    "    edge_weights = []\n",
    "    outgoing = {} # track of all outgoing edges for a node\n",
    "    incoming = {} # track of all incoming edges for a node\n",
    "    #nodes_with_suffixes = set() # counting number of nodes with an outgoing edge\n",
    "    \n",
    "    # preprocess the reads for kmers\n",
    "    kmers_dict={} # dictionary to store which reads have index kmers\n",
    "    for i in range(len(reads)): # for each read\n",
    "        \n",
    "        incoming[i] = set() # initializing the incoming and outgoing list for this read\n",
    "        outgoing[i] = set()\n",
    "        \n",
    "        for start in range(reads[i].len - min_length + 1): # for all min length kmers in the read\n",
    "            cur_kmer = reads[i].seq[start:start+min_length]\n",
    "            \n",
    "            if cur_kmer in kmers_dict: # if this kmer already in the dictionary\n",
    "                kmers_dict[cur_kmer].add(i) # add the index of this read in the dictionary\n",
    "            else:\n",
    "                kmers_dict[cur_kmer]=set() # create the set and then add the read index\n",
    "                kmers_dict[cur_kmer].add(i)\n",
    "                \n",
    "    # for each read, find the reads that have the same suffix as the prefix of this read\n",
    "    for i in range(len(reads)): # for each read\n",
    "        \n",
    "        kmer_prefix = reads[i].seq[:min_length] # min prefix that needs to be the same\n",
    "        possibleOverlaps = kmers_dict[kmer_prefix] # all reads that contain the prefix\n",
    "        \n",
    "        for r in possibleOverlaps: # check every read in the set\n",
    "            \n",
    "            if r != i: # avoiding overlaps with itself\n",
    "                over_len = overlap(reads[r].seq,reads[i].seq,min_length) # call the overlap function to get the longest overlap\n",
    "                \n",
    "                if over_len != 0: # if there is an overlap\n",
    "                    index = bisect.bisect_left(edge_weights,over_len) # find the insertion point in the sorted weights list\n",
    "                    edge_weights.insert(index, over_len) # add the weight\n",
    "                    edges.insert(index,(r,i)) # add the edge\n",
    "                    outgoing[r].add(i)\n",
    "                    incoming[i].add(r)\n",
    "                    #nodes_with_suffixes.add(r)\n",
    "    \n",
    "    return edges, edge_weights, incoming, outgoing\n",
    "\n",
    "\n",
    "def greedy_shortest_sup(reads,min_length=20):\n",
    "    \n",
    "    '''greaedy function to return the shortest superstrings containing the reads \n",
    "    that have atleast min_length overlap - partial genome assembly'''\n",
    "    \n",
    "    edges,weights,incoming,outgoing=calc_overlap_graph(reads,min_length) # calculating the initial overlap graph\n",
    "    #weights is sorted list, edges is a list according to weights, incoming and outgoing are dictionaries where the key in node index\n",
    "    \n",
    "    Left_Nodes = {i:reads[i] for i in range(len(reads))}# list of reads converted to a dictinary for easy addition and removal \n",
    "    new_node_index = len(reads) # tracking the current index assigned to new nodes\n",
    "    removed_nodes = set() # indices of nodes that have to be removed as we have combined these reads, so that we can check edges\n",
    "    \n",
    "    while edges: # while there are any edges left that need to be combined\n",
    "        \n",
    "        big_over = weights.pop() # the largest weight\n",
    "        node1,node2 = edges.pop() # index of nodes corresponding to the weights\n",
    "        \n",
    "        if node1 in removed_nodes or node2 in removed_nodes: # if any of the two nodes are already removed, go to next iteration\n",
    "            continue\n",
    "            \n",
    "        #print(\"Edges to connect: %d %d\"%(node1,node2))\n",
    "        \n",
    "        #creating a new node with the shortest superstring of node1 and node2\n",
    "        new_node=Read(Left_Nodes[node1].seq+Left_Nodes[node2].seq[big_over:],\n",
    "                      Left_Nodes[node1].qual+Left_Nodes[node2].qual[big_over:],\n",
    "                      Left_Nodes[node1].len+Left_Nodes[node2].len-big_over,\n",
    "                      Left_Nodes[node1].num+Left_Nodes[node2].num)         \n",
    "        \n",
    "        new_edges_weight=set() # set for collecting new edges and weight to be added to the graph\n",
    "        incoming[new_node_index]=set() # initializing the incoming and outgoing for the new node\n",
    "        outgoing[new_node_index]=set()\n",
    "        \n",
    "        # for all incoming edges for node1, recalculating the weight and updating the corresponding dictionaries\n",
    "        for inc in incoming[node1]: \n",
    "            if inc == new_node_index or inc == node1 or inc == node2:# skip the edges we just joined\n",
    "                continue\n",
    "                \n",
    "            #print(\"Incoming node1: %d\"%(inc))\n",
    "            new_weight=overlap(Left_Nodes[inc].seq,new_node.seq,min_length) # recalculating the overlap between the incoming node and new node\n",
    "            new_edges_weight.add((inc,new_node_index,new_weight)) # adding the new edge and weight\n",
    "            incoming[new_node_index].add(inc) # adding the incoming node for the new node\n",
    "           \n",
    "            outgoing[inc].remove(node1) # updating the outgoing for the inc node\n",
    "            outgoing[inc].add(new_node_index)\n",
    "        \n",
    "        # for all outgoing edges for node2, recalculating the weight and updating the corresponding dictionaries\n",
    "        for out in outgoing[node2]: \n",
    "            if out == new_node_index or out == node1 or out == node2:# skip the edges we just joined\n",
    "                continue\n",
    "                \n",
    "            #print(\"Outgoing node2: %d\"%(out))\n",
    "            new_weight=overlap(new_node.seq,Left_Nodes[out].seq,min_length) # recalculating the overlap between the new node and the outgoing node\n",
    "            new_edges_weight.add((new_node_index,out,new_weight)) # adding the new edge and weight\n",
    "            outgoing[new_node_index].add(out) # adding the outgoing node for the new node\n",
    "           \n",
    "            incoming[out].remove(node2) # updating the incoming for the out node\n",
    "            incoming[out].add(new_node_index)\n",
    "        \n",
    "        # for all outgoing edges for node1, recalculating the weight and updating the corresponding dictionaries\n",
    "        for out in outgoing[node1]: \n",
    "            if out == node2 or out == new_node_index or out == node1: # skip the edges we just joined\n",
    "                continue\n",
    "            \n",
    "            #print(\"Outgoing node1: %d\"%(out))\n",
    "            new_weight=overlap(new_node.seq,Left_Nodes[out].seq,min_length) # recalculating the overlap between the new node and the outgoing node\n",
    "            new_edges_weight.add((new_node_index,out,new_weight)) # adding the new edge and weight\n",
    "            outgoing[new_node_index].add(out) # adding the outgoing node for the new node\n",
    "           \n",
    "            incoming[out].remove(node1) # updating the incoming for the out node\n",
    "            incoming[out].add(new_node_index)\n",
    "            \n",
    "        # for all incoming edges for node2, recalculating the weight and updating the corresponding dictionaries\n",
    "        for inc in incoming[node2]:\n",
    "            if inc == node1 or inc == new_node_index or inc == node2: # skip the edges we just joined\n",
    "                continue\n",
    "            \n",
    "            #print(\"Incoming node2: %d\"%(inc))\n",
    "            new_weight=overlap(Left_Nodes[inc].seq,new_node.seq,min_length) # recalculating the overlap between the incoming node and new node\n",
    "            new_edges_weight.add((inc,new_node_index,new_weight)) # adding the new edge and weight\n",
    "            incoming[new_node_index].add(inc) # adding the incoming node for the new node\n",
    "           \n",
    "            outgoing[inc].remove(node2) # updating the outgoing for the inc node\n",
    "            outgoing[inc].add(new_node_index)\n",
    "            \n",
    "        #Updating the graph with the new node and edges - also deleting whatever is easy i.e. the dictionaries\n",
    "        \n",
    "        Left_Nodes[new_node_index]=new_node # add the new node to the graph with the new index\n",
    "        new_node_index+=1 # increment the index\n",
    "        \n",
    "        #adding node1 and node2 as removed and removing the corresponding nodes from the graph\n",
    "        removed_nodes.add(node1)\n",
    "        removed_nodes.add(node2)\n",
    "        del Left_Nodes[node1]\n",
    "        del Left_Nodes[node2]\n",
    "        # deleting the incoming and outgoing list for node1 and node2 as we have created them for the new node\n",
    "        del incoming[node1]\n",
    "        del outgoing[node1]\n",
    "        del incoming[node2]\n",
    "        del outgoing[node2]\n",
    "        \n",
    "        # insert the set of new edges and weights into the edges and the weights sorted list of the graph\n",
    "        for val in new_edges_weight:\n",
    "            \n",
    "            new_1,new_2,new_w=val\n",
    "            index = bisect.bisect_left(weights,new_w)\n",
    "            weights.insert(index, new_w) # add the weight\n",
    "            edges.insert(index,(new_1,new_2)) # add the edge\n",
    "            \n",
    "        #print(edges,weights)\n",
    "        #print(incoming)\n",
    "        #print(outgoing)\n",
    "        \n",
    "        #for k in Left_Nodes.keys(): # print the left over nodes\n",
    "        #    print(k,Left_Nodes[k].seq)\n",
    "            \n",
    "    \n",
    "    return Left_Nodes.values() # returning the left over nodes that could not be concatenated based on this min_distance\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one line tests for the above implemented functions'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''one line tests for the above implemented functions'''\n",
    "#g = readGenome('/Users/swatijain/Documents/Personal/GenomeSpecialization/Course4-assignments/lambda_virus.fa')\n",
    "#print(g[:100])\n",
    "\n",
    "#reads = readFastQ('/Users/swatijain/Documents/Personal/GenomeSpecialization/Course4-assignments/ERR037900_1.first1000.fastq')\n",
    "#print(len(reads))\n",
    "#print(reads[0].seq,reads[0].qual,reads[0].len)\n",
    "\n",
    "#test_seq = 'ATATCGCG'\n",
    "#print(reverseCompliment(test_seq))\n",
    "\n",
    "#p = 'CCC'\n",
    "#ten_as = 'AAAAAAAAAA'\n",
    "#t = ten_as + 'CCC' + ten_as + 'GGG' + ten_as\n",
    "#occurrences = naive_match(p, t, True)\n",
    "#print(occurrences)\n",
    "\n",
    "#p = 'CTGT'\n",
    "#ten_as = 'AAAAAAAAAA'\n",
    "#t = ten_as + 'CTGT' + ten_as + 'CTTT' + ten_as + 'CGGG' + ten_as\n",
    "#occurrences = naive_match(p, t)\n",
    "#print(occurrences)\n",
    "\n",
    "#p = 'word'\n",
    "#t = 'there would have been a time for such a word'\n",
    "#occurrences, num_alignments, num_character_comparisons = naive_match(p, t)\n",
    "#print(occurrences, num_alignments, num_character_comparisons)\n",
    "\n",
    "#p = 'needle'\n",
    "#t = 'needle need noodle needle'\n",
    "#occurrences, num_alignments, num_character_comparisons = naive_match(p, t)\n",
    "#print(occurrences, num_alignments, num_character_comparisons)\n",
    "\n",
    "#p = 'word'\n",
    "#t = 'there would have been a time for such a word'\n",
    "#lowercase_alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "#p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "#occurrences, num_alignments, num_character_comparisons = boyer_moore(p, t, p_bm)\n",
    "#print(occurrences, num_alignments, num_character_comparisons)\n",
    "\n",
    "#p = 'needle'\n",
    "#t = 'needle need noodle needle'\n",
    "#p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "#occurrences, num_alignments, num_character_comparisons = boyer_moore(p, t, p_bm)\n",
    "#print(occurrences, num_alignments, num_character_comparisons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "genome = readGenome('/Users/swatijain/Documents/Personal/GenomeSpecialization/Course4-assignments/lambda_virus.fa')\n",
    "occur = naive_match('AGGAGGTT',genome)\n",
    "print(occur[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922] 799954 984143\n",
      "[56922] 127974 165191\n"
     ]
    }
   ],
   "source": [
    "genome = readGenome('/Users/swatijain/Documents/Personal/GenomeSpecialization/Course4-assignments/chr1.GRCh38.excerpt.fasta')\n",
    "pattern = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "p_bm = BoyerMoore(pattern,'ACGT')\n",
    "occurrences, num_alignments, num_character_comparisons = naive_match(pattern,genome)\n",
    "print(occurrences, num_alignments, num_character_comparisons)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore(pattern,genome,p_bm)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "17\n",
      "60\n",
      "[56922, 84641, 147558, 160729, 191452, 262042, 364263, 657496, 681737, 717706, 160162, 273669, 421221, 429299, 465647, 551134, 724927, 635931, 747359]\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "pattern='GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "#occur=naive_match(pattern,genome,False,2)\n",
    "#print(occur)\n",
    "#len(occur[0])\n",
    "index_t = Index(genome,8)\n",
    "#print(index_t.query('GGCGCGGT'))\n",
    "occur = pigeon_hole_index(pattern,genome,index_t,2)\n",
    "print(occur)\n",
    "print(len(occur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "   \n",
    "class SubseqIndex(object):\n",
    "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
    "    \n",
    "    def __init__(self, t, k, ival):\n",
    "        \"\"\" Create index from all subsequences consisting of k characters\n",
    "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
    "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
    "        self.k = k  # num characters per subsequence extracted\n",
    "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
    "        self.index = []\n",
    "        self.span = 1 + ival * (k - 1)\n",
    "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
    "            self.index.append((t[i:i+self.span:ival], i))  # add (subseq, offset)\n",
    "        self.index.sort()  # alphabetize by subseq\n",
    "    \n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
    "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
    "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != subseq:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "29\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "index_subseq=SubseqIndex(genome,8,3)\n",
    "pattern='GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "hits=index_subseq.query((pattern))\n",
    "print(len(hits))\n",
    "hits=index_subseq.query((pattern[1:]))\n",
    "print(len(hits))\n",
    "hits=index_subseq.query((pattern[2:]))\n",
    "print(len(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "genome = readGenome('/Users/swatijain/Documents/Personal/GenomeSpecialization/Course4-assignments/chr1.GRCh38.excerpt.fasta')\n",
    "pattern = 'GATTTACCAGATTGAG'\n",
    "print(edit_dist_match(pattern,genome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(overlap('AAABBCDEBBC','BBCDEBBC###',3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges to connect: 3 0\n",
      "Incoming node1: 1\n",
      "Incoming node1: 2\n",
      "Outgoing node2: 1\n",
      "Outgoing node2: 2\n",
      "Outgoing node2: 4\n",
      "Outgoing node2: 5\n",
      "Outgoing node1: 2\n",
      "Outgoing node1: 4\n",
      "Incoming node2: 1\n",
      "[(6, 5), (2, 6), (6, 1), (0, 5), (3, 4), (2, 3), (3, 2), (0, 1), (1, 0), (6, 4), (1, 6), (6, 2), (4, 5), (0, 4), (1, 3), (0, 2), (2, 1)] [4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "{1: {2, 6}, 2: {6}, 4: {6}, 5: {4, 6}, 6: {1, 2}}\n",
      "{1: {6}, 2: {1, 6}, 4: {5}, 5: set(), 6: {1, 2, 4, 5}}\n",
      "1 TACGTA\n",
      "2 GTACGT\n",
      "4 GTACGA\n",
      "5 TACGAT\n",
      "6 ACGTACG\n",
      "Edges to connect: 2 1\n",
      "Incoming node1: 6\n",
      "Outgoing node2: 6\n",
      "Outgoing node1: 6\n",
      "Incoming node2: 6\n",
      "[(6, 5), (2, 6), (6, 1), (0, 5), (3, 4), (2, 3), (3, 2), (0, 1), (1, 0), (7, 6), (6, 7), (6, 4), (1, 6), (6, 2), (4, 5), (0, 4), (1, 3), (0, 2)] [4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "{4: {6}, 5: {4, 6}, 6: {7}, 7: {6}}\n",
      "{4: {5}, 5: set(), 6: {4, 5, 7}, 7: {6}}\n",
      "4 GTACGA\n",
      "5 TACGAT\n",
      "6 ACGTACG\n",
      "7 GTACGTA\n",
      "Edges to connect: 4 5\n",
      "Incoming node1: 6\n",
      "Incoming node2: 6\n",
      "[(6, 5), (2, 6), (6, 1), (0, 5), (3, 4), (2, 3), (3, 2), (0, 1), (1, 0), (6, 8), (7, 6), (6, 7), (6, 4), (1, 6), (6, 2)] [4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5]\n",
      "{6: {7}, 7: {6}, 8: {6}}\n",
      "{6: {7, 8}, 7: {6}, 8: set()}\n",
      "6 ACGTACG\n",
      "7 GTACGTA\n",
      "8 GTACGAT\n",
      "Edges to connect: 6 7\n",
      "Outgoing node1: 8\n",
      "[(9, 8), (6, 5), (2, 6), (6, 1), (0, 5), (3, 4), (2, 3), (3, 2), (0, 1), (1, 0), (6, 8), (7, 6)] [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5]\n",
      "{8: {9}, 9: set()}\n",
      "{8: set(), 9: {8}}\n",
      "8 GTACGAT\n",
      "9 ACGTACGTA\n",
      "Edges to connect: 9 8\n",
      "[] []\n",
      "{10: set()}\n",
      "{10: set()}\n",
      "10 ACGTACGTAGTACGAT\n",
      "ACGTACGTAGTACGAT\n"
     ]
    }
   ],
   "source": [
    "allreads=readFastQ('/Users/swatijain/Documents/Personal/GenomeSpecialization/Course4-assignments/test_fastq.fastq')\n",
    "#for r in allreads:\n",
    "#    print(r.seq)\n",
    "#edges,weights,incoming,outgoing=calc_overlap_graph(allreads,4)\n",
    "#print(edges,weights)\n",
    "#print(incoming)\n",
    "#print(outgoing)\n",
    "assembled=greedy_shortest_sup(allreads,4)\n",
    "for r in assembled:\n",
    "    print(r.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904746 7161\n"
     ]
    }
   ],
   "source": [
    "allreads=readFastQ('/Users/swatijain/Documents/Personal/GenomeSpecialization/Course4-assignments/ERR266411_1.for_asm.fastq')\n",
    "edges,nodes=calc_overlap_graph(allreads,30)\n",
    "print(len(edges),len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def scs(ss):\n",
    "    \"\"\" Returns shortest common superstring of given\n",
    "        strings, which must be the same length \"\"\"\n",
    "    shortest_sup = None\n",
    "    all_shortest = []\n",
    "    for ssperm in itertools.permutations(ss):\n",
    "        sup = ssperm[0]  # superstring starts as first string\n",
    "        for i in range(len(ss)-1):\n",
    "            # overlap adjacent strings A and B in the permutation\n",
    "            olen = overlap(ssperm[i], ssperm[i+1], min_length=1)\n",
    "            # add non-overlapping portion of B to superstring\n",
    "            sup += ssperm[i+1][olen:]\n",
    "        if shortest_sup is None or len(sup) < len(shortest_sup):\n",
    "            shortest_sup = sup  # found shorter superstring\n",
    "            all_shortest = [] # reset the list of shortest sequences\n",
    "            all_shortest.append(sup)\n",
    "        elif len(sup) == len(shortest_sup): # if the same length\n",
    "            all_shortest.append(sup)\n",
    "            \n",
    "    return all_shortest  # return shortest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TCGATGCAATAG', 'TCGATAGAATGC', 'TCGAATAGATGC', 'TGCAATCGATAG', 'TGCAATAGATCG', 'AATCGATAGTGC', 'AATGCTCGATAG', 'AATAGATCGTGC', 'AATAGATGCTCG', 'AATAGTCGATGC']\n"
     ]
    }
   ],
   "source": [
    "#ss=['CCT','CTT','TGC','TGG','GAT','ATT']\n",
    "strings = ['GAT', 'TAG', 'TCG', 'TGC', 'AAT', 'ATA']\n",
    "#print(scs(ss))\n",
    "print(scs(strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCAAACAAAGTTGGGTAAGGATAGATCAATCAATGATCATATTCTAGTACACTTAGGATTCAAGATCCTATTATCAGGGACAAGAGCAGGATTAGGGATATCCGAGATGGCCACACTTTTGAGGAGCTTAGCATTGTTCAAAAGAAACAAGGACAAACCACCCATTACATCAGGATCCGGTGGAGCCATCAGAGGAATCAAACACATTATTATAGTACCAATTCCTGGAGATTCCTCAATTACCACTCGATCCAGACTACTGGACCGGTTGGTCAGGTTAATTGGAAACCCGGATGTGAGCGGGCCCAAACTAACAGGGGCACTAATAGGTATATTATCCTTATTTGTGGAGTCTCCAGGTCAATTGATTCAGAGGATCACCGATGACCCTGACGTTAGCATCAGGCTGTTAGAGGTTGTTCAGAGTGACCAGTCACAATCTGGCCTTACCTTCGCATCAAGAGGTACCAACATGGAGGATGAGGCGGACCAATACTTTTCACATGATGATCCAAGCAGTAGTGATCAATCCAGGTCCGGATGGTTCGAGAACAAGGAAATCTCAGATATTGAAGTGCAAGACCCTGAGGGATTCAACATGATTCTGGGTACCATTCTAGCCCAGATCTGGGTCTTGCTCGCAAAGGCGGTTACGGCCCCAGACACGGCAGCTGATTCGGAGCTAAGAAGGTGGATAAAGTACACCCAACAAAGAAGGGTAGTTGGTGAATTTAGATTGGAGAGAAAATGGTTGGATGTGGTGAGGAACAGGATTGCCGAGGACCTCTCTTTACGCCGATTCATGGTGGCTCTAATCCTGGATATCAAGAGGACACCCGGGAACAAACCTAGGATTGCTGAAATGATATGTGACATTGATACATATATCGTAGAGGCAGGATTAGCCAGTTTTATCCTGACTATTAAGTTTGGGATAGAAACTATGTATCCTGCTCTTGGACTGCATGAATTTGCTGGTGAGTTATCCACACTTGAGTCCTTGATGAATCTTTACCAGCAAATGGGAGAAACTGCACCCTACATGGTAATCCTAGAGAACTCAATTCAGAACAAGTTCAGTGCAGGATCATACCCTCTGCTCTGGAGCTATGCCATGGGAGTAGGAGTGGAACTTGAAAACTCCATGGGAGGTTTGAACTTTGGTCGATCTTACTTTGATCCAGCATATTTTAGATTAGGGCAAGAGATGGTGAGGAGGTCAGCTGGAAAGGTCAGTTCCACATTGGCATCCGAACTCGGTATCACTGCCGAGGATGCAAGGCTTGTTTCAGAGATTGCAATGCATACTACTGAGGACAGGATCAGTAGAGCGGTCGGACCCAGACAAGCCCAAGTGTCATTTCTACACGGTGATCAAAGTGAGAATGAGCTACCAGGATTGGGGGGCAAGGAAGATAGGAGGGTCAAACAGGGTCGGGGAGAAGCCAGGGAGAGCTACAGAGAAACCGGGTCCAGCAGAGCAAGTGATGCGAGAGCTGCCCATCCTCCAACCAGCATGCCCCTAGACATTGACACTGCATCGGAGTCAGGCCAAGATCCGCAGGACAGTCGAAGGTCAGCTGACGCCCTGCTCAGGCTGCAAGCCATGGCAGGAATCTTGGAAGAACAAGGCTCAGACACGGACACCCCTAGGGTATACAATGACAGAGATCTTCTAGACTAGGTGCGAGAGGCCGAGGACCAGAACAACATCCGCCTACCCTCCATCATTGTTATAAAAAACTTAGGAACCAGGTCCACACAGCCGCCAGCCAACCAACCATCCACTCCCACGACTGGAGCCGATGGCAGAAGAGCAGGCACGCCATGTCAAAAACGGACTGGAATGCATCCGGGCTCTCAAGGCCGAGCCCATCGGCTCACTGGCCGTCGAGGAAGCCATGGCAGCATGGTCAGAAATATCAGACAACCCAGGACAGGACCGAGCCACCTGCAAGGAAGAGGAGGCAGGCAGTTCGGGTCTCAGCAAACCATGCCTCTCAGCAATTGGATCAACTGAAGGCGGTGCACCTCGCATCCGCGGTCAGGGATCTGGAGAAAGCGATGACGACGCTGAAACTTTGGGAATCCCCTCAAGAAATCTCCAGGCATCAAGCACTGGGTTACAGTGTTATCATGTTTATGATCACAGCGGTGAAGCGGTTAAGGGAATCCAAGATGCTGACTCTATCATGGTTCAATCAGGCCTTGATGGTGATAGCACCCTCTCAGGAGGAGACGATGAATCTGAAAACAGCGATGTGGATATTGGCGAACCTGATACCGAGGGATATGCTATCACTGACCGGGGATCTGCTCCCATCTCTATGGGGTTCAGGGCTTCTGATGTTGAAACTGCAGAAGGAGGGGAGATCCACGAGCTCCTGAAACTCCAATCCAGAGGCAACAACTTTCCGAAGCTTGGGAAAACTCTCAATGTTCCTCCGCCCCCGAACCCCAGTAGGGCCAGCACTTCCGAGACACCCATTAAAAAGGGCACAGACGCGAGATTGGCCTCATTTGGAACGGAGATCGCGTCTTTATTGACAGGTGGTGCAACCCAATGTGCTCGAAAGTCACCCTCGGAACCATCAGGGCCAGGTGCACCTGCGGGGAATGTCCCCGAGTGTGTGAGCAATGCCGCACTGATACAGGAGTGGACACCCGAATCTGGTACCACAATCTCCCCGAGATCCCAGAATAATGAAGAAGGGGGAGACTATTATGATGATGAGCTGTTCTCCGATGTCCAAGACATCAAAACAGCCTTGGCCAAAATACACGAGGATAATCAGAAGATAATCTCCAAGCTAGAATCATTGCTGTTATTGAAGGGAGAAGTTGAGTCAATTAAGAAGCAGATCAACAGGCAAAATATCAGCATATCCACCCTGGAAGGACACCTCTCAAGCATCATGATTGCCATTCCTGGACTTGGGAAGGATCCCAACGACCCCACTGCAGATGTCGAACTCAATCCCGACCTGAAACCCATCATAGGCAGAGATTCAGGCCGAGCACTGGCCGAAGTTCTCAAGAAGCCCGTTGCCAGCCGACAACTCCAGGGAATGACTAATGGACGGACCAGTTCCAGAGGACAGCTGCTGAAGGAATTTCAACTAAAGCCGATCGGGAAAAAGGTGAGCTCAGCCGTCGGGTTTGTTCCTGACACCGGCCCTGCATCACGCAGTGTAATCCGCTCCATTATAAAATCCAGCCGGCTAGAGGAGGATCGGAAGCGTTACCTGATGACTCTCCTTGATGATATCAAAGGAGCCAACGATCTTGCCAAGTTCCACCAGATGCTGATGAAGATAATAATGAAGTAGCTACAGCTCAACTTACCTGCCAACCCCATGCCAGTCGACCTAATTAGTACAACCTAAATCCATTATAAAAAACTTAGGAGCAAAGTGATTGCCTCCTAAGTTCCACAATGACAGAGATCTACGATTTCGACAAGTCGGCATGGGACATCAAAGGGTCGATCGCTCCGATACAACCTACCACCTACAGTGATGGCAGGCTGGTGCCCCAGGTCAGAGTCATAGATCCTGGTCTAGGTGATAGGAAGGATGAATGCTTTATGTACATGTTTCTGCTGGGGGTTGTTGAGGACAGCGATCCCCTAGGGCCTCCAATCGGGCGAGCATTCGGGTCCCTGCCCTTAGGTGTTGGTAGATCCACAGCAAAACCCGAGGAACTCCTCAAAGAGGCCACTGAGCTTGACATAGTTGTTAGACGTACAGCAGGGCTCAATGAAAAACTGGTGTTCTACAACAACACCCCACTAACCCTCCTCACACCTTGGAGAAAGGTCCTAACAACAGGGAGTGTCTTCAATGCAAACCAAGTGTGCAATGCGGTTAATCTAATACCGCTGGACACCCCGCAGAGGTTCCGTGTTGTTTATATGAGCATCACCCGTCTTTCGGATAACGGGTATTACACCGTTCCCAGAAGAATGCTGGAATTCAGATCGGTCAATGCAGTGGCCTTCAACCTGCTAGTGACCCTTAGGATTGACAAGGCGATTGGCCCTGGGAAGATCATCGACAATGCAGAGCAACTTCCTGAGGCAACATTTATGGTCCACATCGGGAACTTCAGGAGAAAGAAGAGTGAAGTCTACTCTGCCGATTATTGCAAAATGAAAATCGAAAAGATGGGCCTGGTTTTTGCACTTGGTGGGATAGGGGGCACCAGTCTTCACATTAGAAGCACAGGCAAAATGAGCAAGACTCTCCATGCACAACTCGGGTTCAAGAAGACCTTATGTTACCCACTGATGGATATCAATGAAGACCTTAATCGGTTACTCTGGAGGAGCAGATGCAAGATAGTAAGAATCCAGGCAGTTTTGCAGCCATCAGTTCCTCAAGAATTCCGCATTTACGACGACGTGATCATAAATGATGACCAAGGACTATTCAAAGTTCTGTAGACCGCAGTGCCCAGCAATACCCGAAAACGACCCCCCTCATAATGACAGCCAGAAGGCCCGGACAAAAAAGCCCCCTCCAGAAGACTCCACGGACCAAGCGAGAGGCCAGCCAGCAGCCGACAGCAAGTGTGGACACCAGGCGGCCCAAGCACAGAACAGCCCCGACACAAGGCCACCACCAGCCATCCCAATCTGCGTCCTCCTCGTGGGACCCCCGAGGACCAACCCCGAAGGTCGCTCCGAACACAGACCACCAACCGCATCCCCACAGCTCCCGGGAAAGGAACCCCCAGCAACTGGAAGGCCCCTCCCCCCCTCCCCCAACGCAAGAACCCCACAACCGAACCGCACAAGCGACCGAGGTGACCCAACCGCAGGCATCCGACTCCTTAGACAGATCCTCTCCCCCCGGCATACTAAACAAAACTTAGGGCCAAGGAACACACACACTCGACAGAACCCAGACCCCGGCCCGCGGCACCGCGCCCCCACCCCCCGAAAACCAGAGGGAGCCCCCAACCAAACCCGCCGGCCCCCCCGGTGCCCACAGGTAGGCACACCAACCCCCGACCAGACCCAGCACCCAGCCACCGACAATCCAAGACGGGGGGCCCCCCCCAAAAAAAGGCCCCCAGGGGCCGACAGCCAGCATCGCGAGGAAGCACACCCACCCCACACACGACCACGGCAACCGAACCAGAGTCCAGACCACCCTGGGCCACCAGCTCCCAGACTCGGCCATCACCCCGCAAAAAGGAAAGGCCACAACCCGCGCACCCCAGCCCCGATCCGGCGGGCAGCCACTCAACCCGAACCAGCACCCAAGAGCGATCCCTGGGGGACCCCCAAACCGCAAAAGACATCAGTATCCCACAGCCTCTCCAAGTCCCCCGGTCTCCTCCTCTTCTCGAAGGGACCAAAAGATCAATCCACCACATCCGACGACACTCAATTCCCCACCCCCAAAGGAGACACCGGGAATCCCAGAATCAAGACTCATCCAGTGTCCATCATGGGTCTCAAGGTGAACGTCTCTGCCATATTCATGGCAGTACTGTTAACTCTCCAAACACCCACCGGTCAAATCCATTGGGGCAATCTCTCTAAGATAGGGGTGGTAGGGATAGGAAGTGCAAGCTACAAAGTTATGACTCGTTCCAGCCATCAATCATTGGTCATAAAATTAATGCCCAATATAACTCTCCTCAATAACTGCACGAGGGTAGAGATCGCAGAATACAGGAGACTACTGAGAACAGTTTTGGAACCAATTAGAGATGCACTTAATGCAATGACCCAGAATATAAGACCGGTTCAGAGTGTAGCTTCAAGTAGGAGACACAAGAGATTTGCGGGAGTTGTCCTGGCAGGTGCGGCCCTAGGCGTTGCCACAGCTGCTCAGATAACAGCCGGCATTGCACTTCACCAGTCCATGCTGAACTCTCAAGCCATCGACAATCTGAGAGCAAGCCTGGAAACTACTAATCAGGCAATTGAGGCAATCAGACAAGCAGGGCAGGAGATGATATTGGCTGTTCAGGGTGTCCAAGACTACATCAATAATGAGCTGATACCGTCTATGAACCAACTATCTTGTGATTTAATCGGCCAGAAGCTAGGGCTCAAATTGCTCAGATACTATACAGAAATCCTGTCATTATTTGGCCCCAGCTTACGGGACCCCATATCTGCGGAGATATCCATCCAGGCTTTGAGCTATGCGCTTGGAGGAGATATCAATAAGGTATTAGAAAAGCTCGGATACAGTGGAGGTGATTTACTGGGCATCTTAGAGAGCAGAGGAATAAAGGCCCGGATAACTCACGTCGACACAGAGTCCTACTTCATTGTACTCAGTATAGCCTATCCGACGCTGTCCGAGATTAAGGGGGTGATTGTCCACCGGCTAGAGGGGGTCTCGTACAATATAGGCTCTCAAGAGTGGTATACCACTGTGCCCAAGTATGTTGCAACCCAAGGGTACCTTATCTCGAATTTTGATGAGTCATCGTGTACTTTCATGCCAGAGGGGACTGTGTGCAGCCAAAATGCCTTGTACCCGATGAGTCCTCTGCTCCAAGAATGCCTCCGGGGGTCCACCAAGTCCTGTGCTCGTACACTCGTATCCGGGTCTTTTGGGAACCGGTTCATTTTATCACAAGGGAACCTAATAGCCAATTGTGCATCAATCCTCTGCAAGTGTTACACAACAGGAACGATCATTAATCAAGACCCTGACAAGATCCTAACATACATTGCTGCCGATCACTGCCCGGTGGTCGAGGTGAACGGTGTGACCATCCAAGTCGGGAGCAGGAGGTATCCGGACGCGGTGTACCTGCACAGAATTGACCTCGGTCCTCCCATATCATTGGAGAGGTTGGACGTAGGGACAAATCTGGGGAATGCAATTGCTAAGTTGGAGGATGCCAAGGAATTGTTGGAGTCATCGGACCAGATATTGAGGAGTATGAAAGGTTTATCGAGCACTAGCATAGTTTACATCCTGATTGCAGTGTGTCTTGGAGGGTTGATAGGGATCCCCGCTTTAATATGTTGCTGCAGGGGGCGCTGTAACAAAAAGGGAGAACAAGTTGGTATGTCAAGACCAGGCCTAAAGCCTGATCTTACAGGGACATCAAAATCCTATGTAAGGTCGCTCTGATCCTCTACAACTCTTGAAACACAGATTTCCCACAAGTCTCCTCTTCGTCATCAAGCAACCACCGCATCCAGCATCAAGCCCACCTGAAATTGTCTCCGGCTTCCCTCTGGCCGAACGATATCGGTAGTTAATTAAAACTTAGGGTGCAAGATCATCCACAATGTCACCACAACGAGACCGAATAAATGCCTTCTACAAAGACAACCCACATCCTAAGGGAAGTAGGATAGTTATTAACAGAGAACATCTTATGATTGATAGACCTTATGTTTTGCTGGCTGTTCTATTCGTCATGTTTCTGAGCTTGATCGGGTTGCTAGCCATTGCAGGCATTAGACTCCATCGTGCAGCCATCTACACCGCAGAGATCCATAAGAGCCTCAGCACCAATCTAGATGTAACTAACTCGATCGAGCATCAGGTCAAGGACGTGCTGACACCACTCTTCAAGATCATTGGTGATGAAGTGGGCCTGAGGACACCTCAGAGATTCACTGACCTAGTGAAATTCATCTCTGACAAAATTAAATTCCTTAATCCGGATAGGGAGTACGACTTCAGAGATCTCACTTGGTGTATCAACCCGCCAGAGAGAATCAAATTGGATTATGATCAATACTGTGCAGATGTGGCTGCTGAAGAACTCATGAATGCATTGGTGAACTCAACTCTACTGGAGGCCAGGGCAACCAATCAGTTCCTAGCTGTCTCAAAGGGAAACTGCTCAGGGCCCACTACAATCAGAGGTCAATTCTCAAACATGTCGCTGTCCCTGTTGGACTTGTATTTAAGTCGAGGTTACAATGTGTCATCTATAGTCACTATGACATCCCAGGGAATGTACGGGGGAACTTACCTAGTGGGAAAGCCTAATCTGAGCAGTAAAGGGTCAGAGTTGTCACAACTGAGCATGCACCGAGTGTTTGAAGTAGGGGTTATCAGAAATCCGGGTTTGGGGGCTCCGGTGTTCCATATGACAAACTATTTTGAGCAACCAGTCAGTAATGATTTCAGCAACTGCATGGTGGCTTTGGGGGAGCTTAAATTCGCAGCCCTCTGTCACAGGGAAGATTCTATCACAATTCCCTATCAGGGGTCAGGGAAAGGTGTCAGCTTCCAGCTCGTCAAGCTAGGTGTCTGGAAATCCCCAACCGACATGCGATCCTGGGTCCCCCTATCAACGGATGATCCAGTGATAGATAGGCTTTACCTCTCATCTCACAGAGGTGTTATCGCTGACAATCAAGCAAAATGGGCTGTCCCGACAACACGGACAGATGACAAGTTGCGAATGGAGACATGCTTCCAGCAGGCGTGTAAGGGTAAAAACCAAGCACTCTGCGAGAATCCCGAGTGGGCACCATTGAAGGATAACAGGATTCCTTCATACGGGGTCTTGTCTGTTAATCTGAGTCTGACAGTTGAGCTTAAAATCAAAATTGCTTCAGGATTCGGGCCATTGATCACACACGGTTCAGGGATGGACCTATACAAAACCAACCACAACAATGTGTATTGGCTGACTATCCCGCCAATGAAGAACCTAGCCTTAGGTGTAATCAACACATTGGAGTGGATACCGAGATTCAAGGTTAGTCCCAACCTCTTCACTGTTCCAATCAAGGAAGCAGGCGAGGACTGCCATGCCCCAACATACCTACCTGCGGAGGTGGATGGTGATGTCAAACTCAGTTCCAATCTGGTAATTCTACCTGGTCAGGATCTCCAATATGTTTTGGCAACCTACGATACTTCCAGGGTTGAACATGCTGTGGTTTATTATGTTTACAGCCCAAGCCGCTCATTTTCTTACTTTTATCCTTTTAGGTTGCCTATAAAGGGGGTCCCAATCGAATTACAAGTGGAATGCTTCACATGGGACAAAAAACTCTGGTGCCGTCACTTCTGTGTGCTTGCGGACTCAGAATCTGGTGGACATATCACTCACTCTGGGATGGTGGGCATGGGAGTCAGCTGCACAGTCACTCGGGAAGATGGAACCAATCGCAGATAGGGCTGCCAGTGAACCGATCACATGATGTCACCCAGACATCAGGCATACCCACTAGTGTGAAATAGACATCAGAATTAAGAAAAACGTAGGGTCCAAGTGGTTTCCCGTTATGGACTCGCTATCTGTCAACCAGATCTTATACCCTGAAGTTCACCTAGATAGCCCGATAGTTACCAATAAGATAGTAGCTATCCTGGAGTATGCTCGAGTCCCTCACGCTTACAGCCTGGAGGACCCTACACTGTGTCAGAACATCAAGCACCGCCTAAAAAACGGATTCTCCAACCAAATGATTATAAACAATGTGGAAGTTGGGAATGTCATCAAGTCCAAGCTTAGGAGTTATCCGGCCCACTCTCATATTCCATATCCAAATTGTAATCAGGATTTATTTAACATAGAAGACAAAGAGTCAACAAGGAAGATCCGTGAGCTCCTAAAAAAGGGAAATTCGCTGTACTCCAAAGTCAGTGATAAGGTTTTCCAATGCCTGAGGGACACTAACTCACGGCTTGGCCTAGGCTCCGAATTGAGGGAGGACATCAAGGAGAAAATTATTAACTTGGGAGTTTACATGCACAGCTCCCAATGGTTTGAGCCCTTTCTGTTTTGGTTTACAGTCAAGACTGAGATGAGGTCAGTGATTAAATCACAAACCCATACTTGCCATAGGAGGAGACACACACCTGTATTCTTCACTGGTAGTTCAGTTGAGCTGTTAATCTCTCGTGACCTTGTTGCTATAATCAGTAAGGAGTCTCAACATGTATATTACCTGACGTTTGAACTGGTTTTGATGTATTGTGATGTCATAGAGGGGAGGTTAATGACAGAGACCGCTATGACCATTGATGCTAGGTATGCAGAACTTCTAGGAAGAGTCAGATACATGTGGAAACTGATAGATGGTTTCTTCCCTGCACTCGGGAATCCAACTTATCAAATTGTAGCCATGCTGGAGCCACTTTCACTTGCTTACCTGCAACTGAGGGATATAACAGTAGAACTCAGAGGTGCTTTCCTTAACCACTGCTTTACTGAAATACATGATGTTCTTGACCAAAACGGGTTTTCTGATGAAGGTACTTATCATGAGTTAATTGAAGCCCTAGATTACATTTTCATAACTGATGACATACATCTGACAGGGGAGATTTTCTCATTTTTCAGAAGTTTCGGCCACCCCAGACTTGAAGCAGTAACGGCTGCTGAAAATGTCAGGAAATACATGAATCAGCCTAAAGTCATTGTGTATGAGACTCTGATGAAAGGTCATGCCATATTTTGTGGAATCATAATCAACGGCTATCGTGACAGGCACGGAGGCAGTTGGCCACCCCTGACCCTCCCCCTGCATGCTGCAGACACAATCCGGAATGCTCAAGCTTCAGGTGAAGGGTTAACACATGAGCAGTGCGTTGATAACTGGAAATCATTTGCTGGAGTGAGATTTGGCTGTTTTATGCCTCTTAGCCTGGACAGTGATCTGACAATGTACCTAAAGGACAAGGCACTTGCTGCTCTCCAAAGGGAATGGGATTCAGTTTACCCGAAAGAGTTCCTGCGTTACGATCCTCCCAAGGGAACCGGGTCACGGAGGCTTGTAGATGTTTTCCTTAATGATTCGAGCTTTGACCCATATGATATGATAATGTATGTCGTAAGTGGAGCCTACCTCCATGACCCTGAGTTCAACCTGTCTTACAGCCTGAAAGAAAAGGAGATCAAGGAAACAGGTAGACTTTTCGCTAAAATGACTTACAAAATGAGGGCATGCCAAGTGATCGCTGAAAATCTAATCTCAAACGGGATTGGCAAGTATTTTAAGGACAATGGGATGGCCAAGGATGAGCACGATTTGACTAAGGCACTCCACACTCTGGCTGTCTCAGGAGTCCCCAAAGATCTCAAAGAAAGTCACAGGGGGGGGCCAGTCTTAAAAACCTACTCCCGAAGCCCAGTCCACACAAGTACCAGGAACGTTAAAGCAGAAAAAGGGTTTGTAGGATTCCCTCATGTAATTCGGCAGAATCAAGACACTGATCATCCGGAGAATATAGAAACCTACGAGACAGTCAGCGCATTTATCACGACTGATCTCAAGAAGTACTGCCTTAATTGGAGATATGAGACCATCAGCTTATTTGCACAGAGGCTAAATGAGATTTACGGATTACCCTCATTTTTTCAGTGGCTGCATAAGAGGCTTGAAACCTCTGTCCTCTATGTAAGTGACCCTCATTGCCCCCCCGACCTTGACGCCCATGTCCCGTTATGCAAAGTCCCCAATGACCAAATCTTCATCAAGTACCCTATGGGAGGTATAGAAGGGTATTGTCAGAAGCTGTGGACCATCAGCACCATTCCCTACTTATACCTGGCTGCTTATGAGAGCGGGGTAAGGATTGCTTCGTTAGTGCAAGGGGACAATCAGACCATAGCCGTAACAAAAAGGGTACCCAGCACATGGCCTTACAACCTTAAGAAACGGGAAGCTGCTAGAGTAACTAGAGATTACTTTGTAATTCTTAGGCAAAGGCTACATGACATTGGCCATCACCTCAAGGCAAATGAGACAATTGTTTCATCACATTTTTTTGTCTATTCAAAAGGAATATATTATGATGGGCTACTTGTGTCCCAATCACTCAAGAGCATCGCAAGATGTGTATTCTGGTCAGAGACTATAGTTGATGAAACAAGGGCAGCATGCAGTAATATTGCTACAACAATGGCTAAAAGCATCGAGAGAGGTTATGACCGTTATCTTGCATATTCCCTGAACGTCCTAAAAGTGATACAGCAAATTTTGATCTCTCTTGGCTTCACAATCAATTCAACCATGACCCGAGATGTAGTCATACCCCTCCTCACAAACAACGATCTCTTAATAAGGATGGCACTGTTGCCCGCTCCTATTGGGGGGATGAATTATCTGAATATGAGCAGGCTGTTTGTCAGAAACATCGGTGATCCAGTAACATCATCAATTGCTGATCTCAAGAGAATGATTCTCGCATCACTAATGCCTGAAGAGACCCTCCATCAAGTAATGACACAACAACCGGGGGACTCTTCATTCCTAGACTGGGCTAGCGACCCTTACTCAGCAAATCTTGTATGCGTCCAGAGCATCACTAGACTCCTCAAGAACATAACTGCAAGGTTTGTCCTAATCCATAGTCCAAACCCAATGTTAAAAGGGTTATTCCATGATGACAGTAAAGAAGAGGACGAGAGACTGGCGGCATTCCTCATGGACAGGCATATTATAGTACCTAGGGCAGCTCATGAAATCCTGGATCATAGTGTCACAGGGGCAAGAGAGTCTATTGCAGGCATGCTAGATACCACAAAAGGCCTGATTCGAGCCAGCATGAGGAAGGGGGGGTTAACCTCTCGAGTGATAACCAGATTGTCCAATTATGACTATGAACAATTTAGAGCAGGGATGGTGCTATTGACAGGAAGAAAGAGAAATGTCCTCATTGACAAAGAGTCATGTTCAGTGCAGCTGGCTAGAGCCCTAAGAAGCCATATGTGGGCAAGACTAGCTCGAGGACGGCCTATTTACGGCCTTGAGGTCCCTGATGTACTAGAATCTATGCGAGGCCACCTTATTCGGCGTCATGAGACATGTGTCATCTGCGAGTGTGGATCAGTCAACTACGGATGGTTTTTTGTCCCCTCGGGTTGCCAACTGGATGATATTGACAAGGAAACATCATCCTTGAGAGTCCCATATATTGGTTCTACCACTGATGAGAGAACAGACATGAAGCTCGCCTTCGTAAGAGCCCCAAGTAGATCCTTGCGATCTGCCGTTAGAATAGCAACAGTGTACTCATGGGCTTACGGTGATGATGATAGCTCTTGGAACGAAGCCTGGTTGTTGGCAAGGCAAAGGGCCAATGTGAGCCTGGAGGAGCTAAGGGTGATCACTCCCATCTCGACTTCGACTAATTTAGCGCATAGGTTGAGGGATCGTAGCACTCAAGTGAAATACTCAGGTACATCCCTTGTCCGAGTGGCAAGGTATACCACAATCTCCAACGACAATCTCTCATTTGTCATATCAGATAAGAAGGTTGATACTAACTTTATATACCAACAAGGAATGCTTCTAGGGTTGGGTGTTTTAGAAACATTGTTTCGACTCGAGAAAGATACTGGATCATCTAACACGGTATTACATCTTCACGTCGAAACAGATTGTTGCGTGATCCCGATGATAGATCATCCCAGGATACCCAGCTCCCGCAAGCTAGAGCTGAGGGCAGAGCTATGTACCAACCCATTGATATATGATAATGCACCTTTAATTGACAGAGATGCAACAAGGCTATACACCCAGAGCCATAGGAGGCACCTTGTGGAATTTGTTACATGGTCCACACCCCAACTATATCACATTCTAGCTAAGTCCACAGCACTATCTATGATTGACCTGGTAACAAAATTTGAGAAGGACCATATGAATGAAATTTCAGCTCTCATAGGGGATGACGATATCAATAGTTTCATAACTGAGTTTCTGCTTATAGAGCCAAGATTATTCACCATCTACTTGGGCCAGTGTGCAGCCATCAATTGGGCATTTGATGTACATTATCATAGACCATCAGGGAAATATCAGATGGGTGAGCTGTTGTCTTCGTTCCTTTCTAGAATGAGCAAAGGAGTGTTTAAGGTGCTTGTCAATGCTCTAAGCCACCCAAAGATCTACAAGAAATTCTGGCATTGTGGTATTATAGAGCCTATCCATGGTCCTTCACTTGATGCTCAAAACTTGCACACAACTGTGTGCAACATGGTTTACACATGCTATATGACCTACCTCGACCTGTTGTTGAATGAAGAGTTAGAAGAGTTCACATTTCTTTTGTGTGAAAGCGATGAGGATGTAGTACCGGACAGATTCGACAACATCCAGGCAAAACACTTGTGTGTTCTGGCAGATTTGTACTGTCAACCAGGGACCTGCCCACCGATTCGAGGTCTAAGGCCGGTAGAGAAATGTGCAGTTCTAACCGATCATATCAAGGCAGAGGCTAGGTTATCTCCAGCAGGATCTTCGTGGAACATAAATCCAATTATTGTAGACCATTACTCATGCTCTCTGACTTATCTCCGTCGAGGATCTATCAAACAGATAAGATTGAGAGTTGATCCAGGATTCATTTTTGACGCCCTCGCTGAGGTAAATGTCAGTCAGCCAAAGGTCGGCAGCAACAACATCTCAAATATGAGCATCAAGGATTTCAGACCTCCACACGATGATGTTGCAAAATTGCTCAAAGATATCAACACAAGCAAGCACAATCTTCCCATTTCAGGGGGTAGTCTCGCCAATTATGAAATCCATGCTTTCCGCAGAATCGGGTTAAACTCATCTGCTTGCTACAAAGCTGTTGAGATATCAACATTAATTAGGAGATGCCTTGAGCCAGGGGAAGACGGCTTGTTCTTGGGTGAGGGGTCGGGTTCTATGTTGATCACTTATAAGGAGATACTAAAACTAAACAAGTGCTTCTATAATAGTGGGGTTTCCGCCAATTCTAGATCTGGTCAAAGGGAATTAGCACCCTATCCCTCCGAAGTTGGCCTTGTCGAACACAGAATGGGAGTAGGTAATATTGTCAAGGTGCTCTTTAACGGGAGGCCCGAAGTCACGTGGGTAGGCAGTATAGATTGCTTCAATTTCATAGTCAGTAATATCCCTACCTCTAGTGTGGGGTTTATCCATTCAGATATAGAGACCTTACCTAACAAAGATACTATAGAGAAGCTAGAGGAATTGGCAGCCATCTTATCGATGGCTCTACTCCTTGGCAAAATAGGATCAATACTGGTGATTAAGCTTATGCCTTTCAGCGGGGATTTTGTTCAGGGATTTATAAGCTATGTAGGGTCTCATTATAGAGAAGTGAACCTTGTCTACCCTAGGTACAGCAACTTCATATCTACTGAATCTTATTTAGTTATGACAGATCTCAAAGCTAACCGGCTAATGAATCCTGAAAAGATCAAGCAGCAGATAATTGAATCATCTGTGCGGACTTCACCTGGACTTATAGGTCACATCCTATCCATTAAGCAACTAAGCTGCATACAAGCAATTGTGGGAGGCGCAGTTAGTAGAGGTGATATCAACCCTATTCTGAAAAAACTTACACCTATAGAGCAGGTGCTGATCAGTTGCGGGTTGGCAATTAACGGACCTAAACTGTGCAAAGAATTAATCCACCATGATGTTGCCTCAGGGCAAGATGGATTGCTTAACTCTATACTCATCCTCTACAGGGAGTTGGCAAGATTCAAAGACAACCAAAGAAGTCAACAAGGGATGTTCCACGCTTACCCCGTATTGGTAAGTAGTAGGCAACGAGAACTTGTATCTAGGATCACTCGCAAATTTTGGGGGCATATTCTTCTTTACTCCGGGAACAGAAAGTTGATAAATCGGTTTATCCAGAATCTCAAGTCCGGTTATCTAGTACTAGACTTACACCAGAATATCTTCGTTAAGAATCTATCCAAGTCAGAGAAACAGATTATTATGACGGGGGGTTTAAAACGTGAGTGGGTTTTTAAGGTAACAGTCAAGGAGACCAAAGAATGGTACAAGTTAGTCGGATACAGCGCTCTGATTAAGGATTAATTGGTTGAACTCCGGAACCCTAATCCTGCCCTAGGTAGTTAGGCATTATTTGCAATATATTAAAGAAAACTTTGAAAATACGAAGTTTCTATTCCCAGCTTTGTCTGGT 15894\n",
      "4633\n",
      "3723\n"
     ]
    }
   ],
   "source": [
    "allreads=readFastQ('/Users/swatijain/Documents/Personal/GenomeSpecialization/Course4-assignments/ads1_week4_reads.fq')\n",
    "assembled=greedy_shortest_sup(allreads)\n",
    "for r in assembled:\n",
    "    print(r.seq,len(r.seq))\n",
    "    print(r.seq.count('A'))\n",
    "    print(r.seq.count('T'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
